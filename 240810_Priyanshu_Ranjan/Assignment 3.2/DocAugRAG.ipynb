{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3feeede3-3696-42d5-b026-5046a01b6c7d",
   "metadata": {},
   "source": [
    "# Document Augmentation through Question Generation for Enhanced Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84507781-4793-41e6-bcba-073c5e53b9c2",
   "metadata": {},
   "source": [
    "This implementation demonstrates a text augmentation technique that leverages additional question generation to improve document retrieval within a vector database. By generating and incorporating various questions related to each text fragment, the system enhances the standard retrieval process, thus increasing the likelihood of finding relevant documents that can be utilized as context for generative question answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "200f0573-ef58-4cab-ad70-98e83e2c92f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q llama_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "514ce68a-f548-4407-b949-f7ab5f49f402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1a83af-d92b-45b7-8253-84f3c2b23f70",
   "metadata": {},
   "source": [
    "## Loading Documents and Text Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "029b6d4c-34a8-45cd-91d6-710c9788973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"./data1\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1a5277a-16db-4268-aa2f-c244a8ec69b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/itspriiyanshu/Desktop/Scylla-Agent-25/240810_Priyanshu_Ranjan/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.groq import Groq\n",
    "llm = Groq(model=\"llama3-70b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3ca39d8-5816-4f15-af29-ff6c2db9bcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "embed_model = OllamaEmbedding(model_name=\"nomic-embed-text:latest\")\n",
    "# llm = Ollama(model=\"mistral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "61208aa9-8c55-42f1-89af-0b5d5a7dc14e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "parser = SentenceSplitter(chunk_size=512, chunk_overlap=64)\n",
    "nodes = parser.get_nodes_from_documents(documents)\n",
    "len(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17544cd-086f-4fb5-bf44-71384f7a5c24",
   "metadata": {},
   "source": [
    "## Question Generation and Augmentation\n",
    "\n",
    "This is the standout step from naive RAG. Instead of simply embedding the chunks(docs), we first leverage LLM to generate relevant questions using the chunk as context. Then we augment the chunks with these relevant questions before finally embedding using `VectorStoreIndex`.\n",
    "\n",
    "This enables the retriever to improve the quality of information retrieval in vector-based document search systems. By generating additional questions similar to user queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ed610207-a63e-4017-9ef9-b715b09de3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import NodeWithScore\n",
    "\n",
    "def generate_questions_for_node(node, num_questions=3):\n",
    "    prompt = f\"\"\"Generate {num_questions} relevant questions that could be answered by the following text:\n",
    "\n",
    "\\\"\\\"\\\"{node.text}\\\"\\\"\\\"\n",
    "\n",
    "Questions:\"\"\"\n",
    "    response = llm.complete(prompt)\n",
    "    questions = response.text.strip().split(\"\\n\")\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f8a450f3-cc34-4f48-b4d5-419399497ba2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q generated for Chunk 1\n",
      "Q generated for Chunk 2\n",
      "Q generated for Chunk 3\n",
      "Q generated for Chunk 4\n",
      "Q generated for Chunk 5\n",
      "Q generated for Chunk 6\n",
      "Q generated for Chunk 7\n",
      "Q generated for Chunk 8\n",
      "Q generated for Chunk 9\n",
      "Q generated for Chunk 10\n",
      "Q generated for Chunk 11\n",
      "Q generated for Chunk 12\n",
      "Q generated for Chunk 13\n",
      "Q generated for Chunk 14\n",
      "Q generated for Chunk 15\n",
      "Q generated for Chunk 16\n",
      "Q generated for Chunk 17\n",
      "Q generated for Chunk 18\n",
      "Q generated for Chunk 19\n",
      "Q generated for Chunk 20\n",
      "Q generated for Chunk 21\n",
      "Q generated for Chunk 22\n",
      "Q generated for Chunk 23\n",
      "Q generated for Chunk 24\n",
      "Q generated for Chunk 25\n",
      "Q generated for Chunk 26\n",
      "Q generated for Chunk 27\n",
      "Q generated for Chunk 28\n",
      "Q generated for Chunk 29\n",
      "Q generated for Chunk 30\n",
      "Q generated for Chunk 31\n",
      "Q generated for Chunk 32\n",
      "Q generated for Chunk 33\n",
      "Q generated for Chunk 34\n",
      "Q generated for Chunk 35\n",
      "Q generated for Chunk 36\n",
      "Q generated for Chunk 37\n",
      "Q generated for Chunk 38\n",
      "Q generated for Chunk 39\n",
      "Q generated for Chunk 40\n",
      "Q generated for Chunk 41\n",
      "Q generated for Chunk 42\n",
      "Q generated for Chunk 43\n",
      "Q generated for Chunk 44\n",
      "Q generated for Chunk 45\n",
      "Q generated for Chunk 46\n",
      "Q generated for Chunk 47\n",
      "Q generated for Chunk 48\n",
      "Q generated for Chunk 49\n",
      "Q generated for Chunk 50\n",
      "Q generated for Chunk 51\n",
      "Q generated for Chunk 52\n",
      "Q generated for Chunk 53\n",
      "Q generated for Chunk 54\n",
      "Q generated for Chunk 55\n",
      "Q generated for Chunk 56\n",
      "Q generated for Chunk 57\n",
      "Q generated for Chunk 58\n",
      "Q generated for Chunk 59\n",
      "Q generated for Chunk 60\n",
      "Q generated for Chunk 61\n"
     ]
    }
   ],
   "source": [
    "augmented_nodes = []\n",
    "k = 0\n",
    "for node in nodes:\n",
    "    questions = generate_questions_for_node(node)\n",
    "    question_text = \"\\n\".join(questions)\n",
    "    augmented_text = node.text + \"\\n\\n\" + \"Related Questions:\\n\" + question_text\n",
    "    node.text = augmented_text\n",
    "    augmented_nodes.append(node)\n",
    "    k+=1\n",
    "    print(\"Q generated for Chunk\", k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52021f0-911e-403b-8933-385ae65bb80e",
   "metadata": {},
   "source": [
    "### Example Augmented Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ccd09711-c27d-4c7c-9d71-4fb636b5fb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Air safety, enforced in large \n",
      "part by the certification process of the Federal Aviation Administration ( FAA), was enjoying an \n",
      "exemplary record: Globally, the five-year worldwide average stood at one fatal airliner crash for every \n",
      "2.5 million to 3 million flights. In the United States, airline safety had reached record levels, with only \n",
      "one passenger fatality in more than 10 years.2   \n",
      " \n",
      "Boeing’s initial response to the crash focused on Lion Air’s airline mainte nance procedures and \n",
      "suggested the pilots were at fault.3 Nonetheless, about eight days later, on November 6, 2018, Boeing \n",
      "issued a bulletin to all 737 MAX 8 and 737 MAX 9 operators indicating that “erroneous angle-of-attack \n",
      "data” could result in “uncommanded nose-down movement of the aircraft and that this action can repeat \n",
      "until the related system is deactivated.”4 The Boeing bulletin provided additional instructions to pilots \n",
      "who might encounter such a dangerous situation. On November 7, 2018, the FAA followed by issuing \n",
      "an Emergency Airworthiness Directive requiring Boeing to revise the operating procedures in its flight \n",
      "manual for the 737 MAX aircraft. Of specific concern was the new Maneuvering Characteristics \n",
      "Augmentation System (MCAS), software designed to prevent the aircraft from stalling by automatically\n",
      "\n",
      "Related Questions:\n",
      "Here are three relevant questions that could be answered by the provided text:\n",
      "\n",
      "1. What was the global average of fatal airliner crashes in the five years leading up to the crash mentioned in the text?\n",
      "2. What was the primary focus of Boeing's initial statement regarding the crash, and what did they suggest was at fault?\n",
      "3. What was the specific concern mentioned in the Emergency Airworthiness Directive issued by the FAA on November 7, 2018?\n",
      "\n",
      "Related Questions:\n",
      "Here are three relevant questions that could be answered by the provided text:\n",
      "\n",
      "1. What was the air safety record in the United States in the 10 years leading up to the crash mentioned in the text?\n",
      "2. What did Boeing's bulletin issued on November 6, 2018, warn pilots about regarding the 737 MAX 8 and 737 MAX 9 aircraft?\n",
      "3. How many days passed between the crash and Boeing issuing a bulletin to all 737 MAX 8 and 737 MAX 9 operators?\n"
     ]
    }
   ],
   "source": [
    "print(augmented_nodes[1].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe8d970-72ab-41fa-a7ea-19a1235f3741",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cb48b757-d7b7-44b9-8eb3-27ef0818b091",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "\n",
    "index = VectorStoreIndex(augmented_nodes, embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73155a1-5020-4e0f-a0c8-0c467dfe5ce5",
   "metadata": {},
   "source": [
    "## Retrieval and Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9b62e6ae-a9ab-4349-ba94-b7cb6d6b09e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the provided text, 189 people died in the Lion Air Flight 610 crash, which occurred on October 29, 2018. The main reason for the crash was not explicitly stated in the text, but it was mentioned that the plane commenced its rapid descent at 5,000 feet, just 11 minutes after taking off from Jakarta's Soekarno-Hatta International Airport, and the pilots lost control of the aircraft.\n",
      "The controversies surrounding Boeing's aircraft crashes involve high-stakes public disputes over the root causes of the crashes. Some, like U.S. Congressman Sam Graves, declared that pilots trained in the United States would have been able to handle the emergencies on both jets. Others, however, blamed MCAS and a flawed design process at Boeing. Still, others faulted the FAA. A subsequent report by the U.S. Department of Transportation's Inspector General identified \"limitations in FAA's guidance and processes that impacted certification ….\" These included \"communication gaps,\" \"management and oversight weaknesses,\" and \"process and structure [that] do not ensure [FAA] personnel are adequately independent.\"\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(llm=llm)\n",
    "system_prompt = \"You are a helpful assistant that only responds with accurate and cited information from the context. Responses should be fairly detailed.\"\n",
    "query = \"How many people died in Lion Air crash, when was this and what were the main reasons for the crash?\"\n",
    "response = query_engine.query(f\"{system_prompt}\\n\\n Query : {query}\")\n",
    "print(response)\n",
    "query2 = \"What are the controversies surrounding boeing aircraft's crashes?\"\n",
    "response = query_engine.query(f\"{system_prompt}\\n\\n Query : {query2}\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
